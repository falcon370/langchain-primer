{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa085e95",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), model='gpt-4')\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82238b52",
   "metadata": {},
   "source": [
    "## Easy: Buffer Memory\n",
    "\n",
    "**Task:** Use ConversationBufferMemory to track conversation history\n",
    "\n",
    "**Your task:**\n",
    "1. Create ConversationBufferMemory\n",
    "2. Create ConversationChain with memory\n",
    "3. Have 3-turn conversation:\n",
    "   - Turn 1: \"My name is Alice\"\n",
    "   - Turn 2: \"What's my name?\"\n",
    "   - Turn 3: Something else\n",
    "4. Verify memory works (chain remembers your name)\n",
    "\n",
    "**Hints:**\n",
    "- Memory stores conversation automatically\n",
    "- ConversationChain accepts `llm` and `memory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create memory\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# TODO: Create conversation chain\n",
    "# conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# TODO: Have 3-turn conversation\n",
    "# response1 = conversation.invoke({\"input\": \"My name is Alice\"})\n",
    "# print(f\"Turn 1: {response1['response']}\\n\")\n",
    "\n",
    "# response2 = conversation.invoke({\"input\": \"What's my name?\"})\n",
    "# print(f\"Turn 2: {response2['response']}\\n\")\n",
    "\n",
    "# response3 = conversation.invoke({\"input\": \"Tell me a joke\"})\n",
    "# print(f\"Turn 3: {response3['response']}\")\n",
    "\n",
    "print(\"✅ Easy complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
